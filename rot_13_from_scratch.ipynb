{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rot-13_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CpbGF_HjM-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from codecs import encode"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgzCmiFOz82T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabet = \"abcdefghjiklmnopqrstuvxwyz\"\n",
        "alphabet_characters = [char for char in alphabet]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bVOE4BSztZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(inputs, hidden_weights, hidden_bias, output_weights, output_bias):\n",
        "  hidden_layer_activation = np.dot(inputs, hidden_weights) + hidden_bias\n",
        "  hidden_layer_output = sigmoid_activation(hidden_layer_activation)\n",
        "  output_layer_activation = np.dot(hidden_layer_output, output_weights) + output_bias\n",
        "  predicted = sigmoid_activation(output_layer_activation)\n",
        "  return predicted, hidden_layer_output\n",
        "\n",
        "def backward_propagation(error, predicted, hidden_layer_output, output_weights):\n",
        "  derivative_predicted = error * sigmoid_derivative(predicted)\n",
        "  hidden_layer_error = derivative_predicted.dot(output_weights.T)\n",
        "  derivative_hidden_layer = hidden_layer_error * sigmoid_derivative(hidden_layer_output)\n",
        "  return derivative_predicted, derivative_hidden_layer\n",
        "\n",
        "def update_weights(inputs, hidden_weights, hidden_bias, output_weights, output_bias, hidden_layer_output, derivative_predicted, derivative_hidden_layer, eta):\n",
        "  output_weights += hidden_layer_output.T.dot(derivative_predicted) * eta\n",
        "  output_bias += np.sum(derivative_predicted, axis=0, keepdims=True) * eta\n",
        "  hidden_weights += inputs.T.dot(derivative_hidden_layer) * eta\n",
        "  hidden_bias += np.sum(derivative_hidden_layer, axis=0, keepdims=True) * eta\n",
        "  return output_weights, output_bias, hidden_weights, hidden_bias\n",
        "\n",
        "def sigmoid_activation(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return x * (1 - x)\n",
        "\n",
        "def mlp_start_weights(mlp_input, mlp_hidden, mlp_output):\n",
        "  hidden_weights = np.random.uniform(size=(mlp_input, mlp_hidden))\n",
        "  hidden_bias = np.random.uniform(size=(1, mlp_hidden))\n",
        "  output_weights = np.random.uniform(size=(mlp_hidden, mlp_output))\n",
        "  output_bias = np.random.uniform(size=(1, mlp_output))\n",
        "  return hidden_weights, hidden_bias, output_weights, output_bias"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aY83vHqzv4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "identity_n = 26\n",
        "encoder_input = np.identity(identity_n)\n",
        "encoder_output = np.roll(np.identity(identity_n), identity_n//2, axis=0)\n",
        "\n",
        "eta = 0.01\n",
        "stop_value = 0.0001\n",
        "max_iter = 500000\n",
        "mlp_input_hidden_output = (identity_n, int(math.log(identity_n,2)), identity_n) # Duas camadas de entrada, duas intermediárias, uma de saída\n",
        "\n",
        "error_output_layer = math.inf\n",
        "input_size, hidden_size, output_size = mlp_input_hidden_output\n",
        "hidden_weights, hidden_bias, output_weights, output_bias = mlp_start_weights(input_size, hidden_size, output_size)\n",
        "\n",
        "# Treinamento do MLP\n",
        "for _ in range(max_iter):\n",
        "  if error_output_layer < stop_value: # Cancela treinamento se erro ja chegou no valor de parada\n",
        "    break\n",
        "  \n",
        "  predicted, hidden_layer_output = forward_propagation(encoder_input, hidden_weights, hidden_bias, output_weights, output_bias)\n",
        "  error = encoder_output - predicted\n",
        "  derivative_predicted, derivative_hidden_layer = backward_propagation(error, predicted, hidden_layer_output, output_weights)\n",
        "  output_weights, output_bias, hidden_weights, hidden_bias = update_weights(encoder_input, hidden_weights, hidden_bias, output_weights, output_bias, hidden_layer_output, derivative_predicted, derivative_hidden_layer, eta)\n",
        "  error_output_layer = abs(error[-1][0])\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIkZsu8-zzcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string_to_encode = \"hygenfrpergzrffntr\"\n",
        "string_to_encode_characters = [char for char in string_to_encode]\n",
        "letter_positions = np.searchsorted(alphabet_characters, string_to_encode_characters)\n",
        "\n",
        "word = np.zeros((len(letter_positions), len(alphabet_characters)))\n",
        "for index, letter in enumerate(letter_positions):\n",
        "  word[index][letter] = 1"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW7vss-Zz1uQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted, hidden_layer_output = forward_propagation(word, hidden_weights, hidden_bias, output_weights, output_bias)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWctTl7Az3Fw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b737482b-36e1-4828-fea1-18e936624de9"
      },
      "source": [
        "print(\"Original message:  %s\" % string_to_encode)\n",
        "print(\"Predicted message: \", end='')\n",
        "for one_hot_encoded_letter in np.round(predicted):\n",
        "  for encoded_letter, letter in zip(one_hot_encoded_letter, alphabet_characters):\n",
        "    if encoded_letter and letter:\n",
        "      print(letter, end='')\n",
        "\n",
        "print(\"\\nRight message:\\t   %s\" % encode(string_to_encode, \"rot_13\"))\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original message:  hygenfrpergzrffntr\n",
            "Predicted message: ultrasecretmessage\n",
            "Right message:\t   ultrasecretmessage\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToIrMBqZ7DiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}